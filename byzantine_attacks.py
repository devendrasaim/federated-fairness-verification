# -*- coding: utf-8 -*-
"""Byzantine_Attacks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vy4ot7g7txV65ADwmTYeFbHJUgfBPzVY

PROJECT TITLE: Defense-Aware Federated Learning for Robustness Against Adversarial
and Byzantine Attacks
"""

"""Project Description:

This project aims to implement a federated learning (FL) system resilient to
adversarial attacks and Byzantine clients. Federated learning allows distributed
model training across multiple clients without sharing raw data, making it
vulnerable to attacks from malicious or faulty clients. This project combines
adversarial training and Byzantine-resilient aggregation to enhance the robustness
of the global model against these threats. The system is designed to adapt to non
IID data and partial client participation, mimicking real-world FL scenarios where
data distributions and client reliability vary.

Project Objectives:

• Develop a robust federated learning system that integrates adversarially robust
learning and Byzantine-resilient aggregation.

• Implement adversarial training on clients to harden the model against
perturbed data, enhancing model resilience.

• Use Byzantine Krum aggregation to limit the impact of malicious clients,
selecting updates close to the majority and ignoring outliers.

• Evaluate model performance and robustness on real-world datasets, such as
MNIST, against attacks in federated settings.

• Analyze the system's effectiveness and limitations in maintaining high
performance even when some clients act adversarially or have faulty data.
"""

import tensorflow as tf
import numpy as np
from scipy.spatial.distance import euclidean
import matplotlib.pyplot as plt
import tensorflow_federated as tff
from tensorflow.keras.preprocessing.image import ImageDataGenerator # Import ImageDataGenerator

# Constants
EPSILON = 0.001  # For adversarial example generation
NUM_CLIENTS = 10
BYZANTINE_CLIENT_RATIO = 0.2  # Proportion of malicious clients
EPOCHS_PER_CLIENT = 2  # Increase training epochs for clients

# Load and preprocess MNIST dataset
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
train_images = train_images[..., np.newaxis].astype('float32') / 255.0
test_images = test_images[..., np.newaxis].astype('float32') / 255.0

# Step 1: Define an Improved Model Architecture
def create_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    return model

# Step 2: Define Adversarial Example Generation (FGSM (Fast Gradient Sign Method) )
def generate_adversarial_example(model, x, y, epsilon=EPSILON):
    # Convert NumPy array to tf.Tensor explicitly
    x = tf.convert_to_tensor(x, dtype=tf.float32)
    with tf.GradientTape() as tape:
        tape.watch(x)
        prediction = model(x)
        loss = tf.keras.losses.sparse_categorical_crossentropy(y, prediction)
    gradient = tape.gradient(loss, x)
    adversarial_x = x + epsilon * tf.sign(gradient)
    return tf.clip_by_value(adversarial_x, 0, 1)

# Step 3: Client Training with Improvements
def client_training(model, data, is_malicious=False):
    x, y = data
    if is_malicious:
        x = generate_adversarial_example(model, x, y)
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                  metrics=['accuracy'])
    model.fit(x, y, epochs=EPOCHS_PER_CLIENT, verbose=0)
    return model.get_weights()

# Step 4: Robust Aggregation - Byzantine Krum
def byzantine_krum_aggregation(client_weights):
    num_clients = len(client_weights)
    distances = np.zeros((num_clients, num_clients))



    flattened_weights = [np.concatenate([w.flatten() for w in weights]) for weights in client_weights]

    for i in range(num_clients):
        for j in range(i + 1, num_clients):
            distances[i, j] = euclidean(flattened_weights[i], flattened_weights[j])
            distances[j, i] = distances[i, j]

    scores = []
    f = int(BYZANTINE_CLIENT_RATIO * num_clients)
    for i in range(num_clients):
        dists = sorted(distances[i])
        score = sum(dists[:num_clients - f - 1])
        scores.append((score, i))

    scores.sort()
    best_client_index = scores[0][1]
    return client_weights[best_client_index]

# Step 5: Federated Training with Improvements
def federated_training():
    global_model = create_model()
    global_weights = global_model.get_weights()

    loss_history = []
    accuracy_history = []

    for round in range(5):
        client_weights = []
        for client_id in range(NUM_CLIENTS):
            model = create_model()
            model.set_weights(global_weights)

            is_malicious = (client_id < int(BYZANTINE_CLIENT_RATIO * NUM_CLIENTS))

            # Assign subset of MNIST data to each client
            client_data_indices = np.random.choice(len(train_images), 500, replace=False)
            client_data = (train_images[client_data_indices], train_labels[client_data_indices])

            client_weights.append(client_training(model, client_data, is_malicious=is_malicious))

        global_weights = byzantine_krum_aggregation(client_weights)
        global_model.set_weights(global_weights)

        global_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                            loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                            metrics=['accuracy'])

        # Evaluate the global model on the test set
        loss, accuracy = global_model.evaluate(test_images, test_labels, verbose=0)
        loss_history.append(loss)
        accuracy_history.append(accuracy)

        print(f"Round {round + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}")


    # Plotting accuracy and loss
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(range(1, 6), accuracy_history, marker='o')
    plt.title('Federated Learning Accuracy over Rounds')
    plt.xlabel('Round')
    plt.ylabel('Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(range(1, 6), loss_history, marker='o')
    plt.title('Federated Learning Loss over Rounds')
    plt.xlabel('Round')
    plt.ylabel('Loss')

    plt.tight_layout()
    plt.show()

# Run Federated Training with MNIST
federated_training()



